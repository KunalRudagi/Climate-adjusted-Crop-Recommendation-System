# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h7bPlu4SxAon-X4AmtKyP9n_ivPry1hn
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from keras.models import Sequential
from keras.layers import Dense

# Load the dataset
data = pd.read_csv('/content/main merge (droped _merge==2) (560 dist 1990-2015).csv',sep=';', on_bad_lines='skip', decimal=',')
  # Replace with your file path
display(data.head())

# Select input features (climatic conditions)
features = data.loc[:, ['Winter JAN-FEB MAXIMUM TEMPERATURE (Centigrate)',
                 'Summer MAR-MAY MAXIMUM TEMPERATURE (Centigrate)',
                 'Rainy JUN-SEP MAXIMUM TEMPERATURE (Centigrate)',
                 'Autumn OCT-DEC MAXIMUM TEMPERATURE (Centigrate)',
                 'Winter JAN-FEB MINIMUM TEMPERATURE (Centigrate)',
                 'Summer MAR-MAY MINIMUM TEMPERATURE (Centigrate)',
                 'Rainy JUN-SEP MINIMUM TEMPERATURE (Centigrate)',
                 'Autumn OCT-DEC MINIMUM TEMPERATURE (Centigrate)',
                 'Winter JAN-FEB PERCIPITATION (Millimeters)',
                 'Summer MAR-MAY PERCIPITATION (Millimeters)',
                 'Rainy JUN-SEP PERCIPITATION (Millimeters)',
                 'Autumn OCT-DEC PERCIPITATION (Millimeters)',
                 'Winter JAN-FEB WINDSPEED (Meter per second)',
                 'Summer MAR-MAY WINDSPEED (Meter per second)',
                 'Rainy JUN-SEP WINDSPEED (Meter per second)',
                 'Autumn OCT-DEC WINDSPEED (Meter per second)',
                 'NITROGEN CONSUMPTION (tons)',
                 'PHOSPHATE CONSUMPTION (tons)',
                 'POTASH CONSUMPTION (tons)']]


# Convert features to numeric, errors='coerce' will convert invalid values to NaN
for col in features.columns:
    features.loc[:,col] = pd.to_numeric(features[col], errors='coerce')


# Target variables (yields for all crops)
targets = data.loc[:, ['RICE YIELD (Kg per ha)',
                'PEARL MILLET YIELD (Kg per ha)',
                'CHICKPEA YIELD (Kg per ha)',
                'GROUNDNUT YIELD (Kg per ha)',
                'SUGARCANE YIELD (Kg per ha)']]

# Apply infer_objects() before fillna
features = features.infer_objects()
targets = targets.infer_objects()

# Handle missing values using .loc
features.loc[:, features.columns] = features.fillna(features.mean())
targets.loc[:, targets.columns] = targets.fillna(targets.mean())


# Scale input features
scaler = StandardScaler()
features_scaled = scaler.fit_transform(features)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(features_scaled, targets, test_size=0.2, random_state=42)

# Define the ANN model
model = Sequential()
model.add(Dense(128, activation='relu', input_dim=X_train.shape[1]))  # Input layer
model.add(Dense(64, activation='relu'))  # Hidden layer
model.add(Dense(32, activation='relu'))  # Hidden layer
model.add(Dense(y_train.shape[1], activation='linear'))  # Output layer (one neuron per crop)

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])

# Train the model
history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2)

# Evaluate the model
loss, mae = model.evaluate(X_test, y_test)
print(f"Mean Absolute Error: {mae}")

# Example farmer input for climatic conditions
farmer_input = {
    'Winter MAX TEMP': 25, 'Summer MAX TEMP': 35,
    'Rainy MAX TEMP': 30, 'Autumn MAX TEMP': 28,
    'Winter MIN TEMP': 12, 'Summer MIN TEMP': 18,
    'Rainy MIN TEMP': 20, 'Autumn MIN TEMP': 15,
    'Winter PERCIPITATION': 50, 'Summer PERCIPITATION': 100,
    'Rainy PERCIPITATION': 300, 'Autumn PERCIPITATION': 80,
    'Winter WINDSPEED': 2, 'Summer WINDSPEED': 3,
    'Rainy WINDSPEED': 2.5, 'Autumn WINDSPEED': 2,
    'NITROGEN CONSUMPTION': 100,
    'PHOSPHATE CONSUMPTION': 50,
    'POTASH CONSUMPTION': 75
}

# Convert input into a scaled array
input_array = scaler.transform([[
    farmer_input['Winter MAX TEMP'], farmer_input['Summer MAX TEMP'],
    farmer_input['Rainy MAX TEMP'], farmer_input['Autumn MAX TEMP'],
    farmer_input['Winter MIN TEMP'], farmer_input['Summer MIN TEMP'],
    farmer_input['Rainy MIN TEMP'], farmer_input['Autumn MIN TEMP'],
    farmer_input['Winter PERCIPITATION'], farmer_input['Summer PERCIPITATION'],
    farmer_input['Rainy PERCIPITATION'], farmer_input['Autumn PERCIPITATION'],
    farmer_input['Winter WINDSPEED'], farmer_input['Summer WINDSPEED'],
    farmer_input['Rainy WINDSPEED'], farmer_input['Autumn WINDSPEED'],
    farmer_input['NITROGEN CONSUMPTION'], farmer_input['PHOSPHATE CONSUMPTION'],
    farmer_input['POTASH CONSUMPTION']
]])

# Predict yields for all crops
predicted_yields = model.predict(input_array)[0]

# Crop names
crops = ['Rice', 'Pearl Millet', 'Chickpea', 'Groundnut', 'Sugarcane']

# Find the best crop
best_crop_index = np.argmax(predicted_yields)
best_crop = crops[best_crop_index]
best_yield = predicted_yields[best_crop_index]

print("Predicted Yields for Crops (Kg/ha):")
for crop, yield_value in zip(crops, predicted_yields):
    print(f"{crop}: {yield_value:.2f}")

print(f"\nBest Crop: {best_crop} with Yield: {best_yield:.2f} Kg/ha")



import matplotlib.pyplot as plt

# Plot training and validation loss
def plot_training_history(history):
    plt.figure(figsize=(12, 6))

    # Loss plot
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Loss vs Epochs')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    # MAE plot
    plt.subplot(1, 2, 2)
    plt.plot(history.history['mae'], label='Training MAE')
    plt.plot(history.history['val_mae'], label='Validation MAE')
    plt.title('Mean Absolute Error (MAE) vs Epochs')
    plt.xlabel('Epochs')
    plt.ylabel('MAE')
    plt.legend()

    plt.tight_layout()
    plt.show()

# Call the function to visualize ANN training metrics
plot_training_history(history)

# Predict yields on test data
y_pred = model.predict(X_test)

# Compare predicted vs actual yields for the first crop (e.g., Rice Yield)
plt.figure(figsize=(10, 6))
plt.scatter(y_test['RICE YIELD (Kg per ha)'], y_pred[:, 0], alpha=0.6)
plt.title('Actual vs Predicted Crop Yield (Rice)')
plt.xlabel('Actual Yield (Kg/ha)')
plt.ylabel('Predicted Yield (Kg/ha)')
plt.plot([y_test['RICE YIELD (Kg per ha)'].min(), y_test['RICE YIELD (Kg per ha)'].max()],
         [y_test['RICE YIELD (Kg per ha)'].min(), y_test['RICE YIELD (Kg per ha)'].max()],
         'r--', label='Ideal Prediction')
plt.legend()
plt.grid()
plt.show()

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

# Predict the yields on the test set
y_pred = model.predict(X_test)

# Initialize a dictionary to store metrics for each crop
metrics = {}

# Iterate through each crop to calculate metrics
for i, crop in enumerate(targets.columns):
    actual = y_test.iloc[:, i]  # Actual values for the crop
    predicted = y_pred[:, i]    # Predicted values for the crop

    # Calculate metrics
    mae = mean_absolute_error(actual, predicted)
    mse = mean_squared_error(actual, predicted)
    rmse = np.sqrt(mse)
    r2 = r2_score(actual, predicted)

    # Store metrics in the dictionary
    metrics[crop] = {
        "MAE": mae,
        "MSE": mse,
        "RMSE": rmse,
        "RÂ²": r2
    }

# Display metrics for each crop
for crop, metric_values in metrics.items():
    print(f"\nMetrics for {crop}:")
    for metric_name, value in metric_values.items():
        print(f"{metric_name}: {value:.2f}")

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Assuming the first model's `features` is already defined, create `features_2`
features_2 = data[['RICE YIELD (Kg per ha)',  # Current yield (or predicted best yield from the first model)
                   'Winter JAN-FEB MAXIMUM TEMPERATURE (Centigrate)',
                   'Summer MAR-MAY MAXIMUM TEMPERATURE (Centigrate)',
                   'Rainy JUN-SEP MAXIMUM TEMPERATURE (Centigrate)',
                   'Autumn OCT-DEC MAXIMUM TEMPERATURE (Centigrate)',
                   'Winter JAN-FEB MINIMUM TEMPERATURE (Centigrate)',
                   'Summer MAR-MAY MINIMUM TEMPERATURE (Centigrate)',
                   'Rainy JUN-SEP MINIMUM TEMPERATURE (Centigrate)',
                   'Autumn OCT-DEC MINIMUM TEMPERATURE (Centigrate)',
                   'Winter JAN-FEB PERCIPITATION (Millimeters)',
                   'Summer MAR-MAY PERCIPITATION (Millimeters)',
                   'Rainy JUN-SEP PERCIPITATION (Millimeters)',
                   'Autumn OCT-DEC PERCIPITATION (Millimeters)',
                   'Winter JAN-FEB WINDSPEED (Meter per second)',
                   'Summer MAR-MAY WINDSPEED (Meter per second)',
                   'Rainy JUN-SEP WINDSPEED (Meter per second)',
                   'Autumn OCT-DEC WINDSPEED (Meter per second)']].copy()

# Target variables: Fertilizer quantities
targets_2 = data[['NITROGEN CONSUMPTION (tons)',
                  'PHOSPHATE CONSUMPTION (tons)',
                  'POTASH CONSUMPTION (tons)']].copy()


# Handle missing values
features_2.fillna(features_2.mean(), inplace=True)
targets_2.fillna(targets_2.mean(), inplace=True)


# Scale input features
scaler_2 = StandardScaler()
features_2_scaled = scaler_2.fit_transform(features_2)

# Split data into training and testing sets
X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(features_2_scaled, targets_2, test_size=0.2, random_state=42)

# Train separate Random Forest Regressors for each fertilizer type
models_2 = {}
for target in targets_2.columns:
    regressor = RandomForestRegressor(n_estimators=100, random_state=42)
    regressor.fit(X_train_2, y_train_2[target])
    models_2[target] = regressor

# Evaluate the models
for target, model in models_2.items():
    predictions = model.predict(X_test_2)
    mae = mean_absolute_error(y_test_2[target], predictions)
    print(f"{target} Mean Absolute Error: {mae:.2f}")

# Example farmer input for climatic conditions and yield (predicted from first model)
farmer_input_2 = {
    'RICE_YIELD': 2500,  # Replace this with the predicted yield from the first model
    'Winter_MAX_TEMP': 25, 'Summer_MAX_TEMP': 35,
    'Rainy_MAX_TEMP': 30, 'Autumn_MAX_TEMP': 28,
    'Winter_MIN_TEMP': 12, 'Summer_MIN_TEMP': 18,
    'Rainy_MIN_TEMP': 20, 'Autumn_MIN_TEMP': 15,
    'Winter_PERCIPITATION': 50, 'Summer_PERCIPITATION': 100,
    'Rainy_PERCIPITATION': 300, 'Autumn_PERCIPITATION': 80,
    'Winter_WINDSPEED': 2, 'Summer_WINDSPEED': 3,
    'Rainy_WINDSPEED': 2.5, 'Autumn_WINDSPEED': 2
}

# Convert farmer input into a scaled array
input_array_2 = scaler_2.transform([[
    farmer_input_2['RICE_YIELD'], farmer_input_2['Winter_MAX_TEMP'], farmer_input_2['Summer_MAX_TEMP'],
    farmer_input_2['Rainy_MAX_TEMP'], farmer_input_2['Autumn_MAX_TEMP'], farmer_input_2['Winter_MIN_TEMP'],
    farmer_input_2['Summer_MIN_TEMP'], farmer_input_2['Rainy_MIN_TEMP'], farmer_input_2['Autumn_MIN_TEMP'],
    farmer_input_2['Winter_PERCIPITATION'], farmer_input_2['Summer_PERCIPITATION'],
    farmer_input_2['Rainy_PERCIPITATION'], farmer_input_2['Autumn_PERCIPITATION'],
    farmer_input_2['Winter_WINDSPEED'], farmer_input_2['Summer_WINDSPEED'],
    farmer_input_2['Rainy_WINDSPEED'], farmer_input_2['Autumn_WINDSPEED']
]])

# Predict recommended fertilizer quantities
predicted_fertilizer_2 = {target: model.predict(input_array_2)[0] for target, model in models_2.items()}

# Display recommended adjustments
print("Recommended Fertilizer Quantities (in tons):")
for fert, value in predicted_fertilizer_2.items():
    print(f"{fert}: {value:.2f} tons")

import pickle

# Save the trained model as a .pkl file
with open('model.pkl', 'wb') as f:
    pickle.dump(model, f)

# Download the file to your local machine
from google.colab import files
files.download('model.pkl')